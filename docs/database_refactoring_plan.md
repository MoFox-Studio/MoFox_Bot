# æ•°æ®åº“æ¨¡å—é‡æ„æ–¹æ¡ˆ

## ğŸ“‹ ç›®å½•
1. [é‡æ„ç›®æ ‡](#é‡æ„ç›®æ ‡)
2. [å¯¹å¤–APIä¿æŒå…¼å®¹](#å¯¹å¤–apiä¿æŒå…¼å®¹)
3. [æ–°æ¶æ„è®¾è®¡](#æ–°æ¶æ„è®¾è®¡)
4. [é«˜é¢‘è¯»å†™ä¼˜åŒ–](#é«˜é¢‘è¯»å†™ä¼˜åŒ–)
5. [å®æ–½è®¡åˆ’](#å®æ–½è®¡åˆ’)
6. [é£é™©è¯„ä¼°ä¸å›æ»šæ–¹æ¡ˆ](#é£é™©è¯„ä¼°ä¸å›æ»šæ–¹æ¡ˆ)

---

## ğŸ¯ é‡æ„ç›®æ ‡

### æ ¸å¿ƒç›®æ ‡
1. **æ¶æ„æ¸…æ™°åŒ–** - æ¶ˆé™¤èŒè´£é‡å ï¼Œæ˜ç¡®æ¨¡å—è¾¹ç•Œ
2. **æ€§èƒ½ä¼˜åŒ–** - é’ˆå¯¹é«˜é¢‘è¯»å†™åœºæ™¯è¿›è¡Œæ·±åº¦ä¼˜åŒ–
3. **å‘åå…¼å®¹** - ä¿æŒæ‰€æœ‰å¯¹å¤–APIæ¥å£ä¸å˜
4. **å¯ç»´æŠ¤æ€§** - æé«˜ä»£ç è´¨é‡å’Œå¯æµ‹è¯•æ€§

### å…³é”®æŒ‡æ ‡
- âœ… é›¶ç ´åæ€§å˜æ›´
- âœ… é«˜é¢‘è¯»å–æ€§èƒ½æå‡ 50%+
- âœ… å†™å…¥æ‰¹é‡åŒ–ç‡æå‡è‡³ 80%+
- âœ… è¿æ¥æ± åˆ©ç”¨ç‡ > 90%

---

## ğŸ”’ å¯¹å¤–APIä¿æŒå…¼å®¹

### è¯†åˆ«çš„å…³é”®APIæ¥å£

#### 1. æ•°æ®åº“ä¼šè¯ç®¡ç†
```python
# âœ… å¿…é¡»ä¿æŒ
from src.common.database.sqlalchemy_models import get_db_session

async with get_db_session() as session:
    # ä½¿ç”¨session
```

#### 2. æ•°æ®æ“ä½œAPI
```python
# âœ… å¿…é¡»ä¿æŒ
from src.common.database.sqlalchemy_database_api import (
    db_query,    # é€šç”¨æŸ¥è¯¢
    db_save,     # ä¿å­˜/æ›´æ–°
    db_get,      # å¿«æ·æŸ¥è¯¢
    store_action_info,  # å­˜å‚¨åŠ¨ä½œ
)
```

#### 3. æ¨¡å‹å¯¼å…¥
```python
# âœ… å¿…é¡»ä¿æŒ
from src.common.database.sqlalchemy_models import (
    ChatStreams,
    Messages,
    PersonInfo,
    LLMUsage,
    Emoji,
    Images,
    # ... æ‰€æœ‰30+æ¨¡å‹
)
```

#### 4. åˆå§‹åŒ–æ¥å£
```python
# âœ… å¿…é¡»ä¿æŒ
from src.common.database.database import (
    db,
    initialize_sql_database,
    stop_database,
)
```

#### 5. æ¨¡å‹æ˜ å°„
```python
# âœ… å¿…é¡»ä¿æŒ
from src.common.database.sqlalchemy_database_api import MODEL_MAPPING
```

### å…¼å®¹æ€§ç­–ç•¥
æ‰€æœ‰ç°æœ‰å¯¼å…¥è·¯å¾„å°†é€šè¿‡ `__init__.py` é‡æ–°å¯¼å‡ºï¼Œç¡®ä¿é›¶ç ´åæ€§å˜æ›´ã€‚

---

## ğŸ—ï¸ æ–°æ¶æ„è®¾è®¡

### å½“å‰æ¶æ„é—®é¢˜
```
âŒ å½“å‰ç»“æ„ - èŒè´£æ··ä¹±
database/
â”œâ”€â”€ database.py              (å…¥å£+åˆå§‹åŒ–+ä»£ç†)
â”œâ”€â”€ sqlalchemy_init.py       (é‡å¤çš„åˆå§‹åŒ–é€»è¾‘)
â”œâ”€â”€ sqlalchemy_models.py     (æ¨¡å‹+å¼•æ“+ä¼šè¯+åˆå§‹åŒ–)
â”œâ”€â”€ sqlalchemy_database_api.py
â”œâ”€â”€ connection_pool_manager.py
â”œâ”€â”€ db_batch_scheduler.py
â””â”€â”€ db_migration.py
```

### æ–°æ¶æ„è®¾è®¡
```
âœ… æ–°ç»“æ„ - èŒè´£æ¸…æ™°
database/
â”œâ”€â”€ __init__.py                    ã€ç»Ÿä¸€å…¥å£ã€‘å¯¼å‡ºæ‰€æœ‰API
â”‚
â”œâ”€â”€ core/                          ã€æ ¸å¿ƒå±‚ã€‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ engine.py                  æ•°æ®åº“å¼•æ“ç®¡ç†ï¼ˆå•ä¸€èŒè´£ï¼‰
â”‚   â”œâ”€â”€ session.py                 ä¼šè¯ç®¡ç†ï¼ˆå•ä¸€èŒè´£ï¼‰
â”‚   â”œâ”€â”€ models.py                  æ¨¡å‹å®šä¹‰ï¼ˆçº¯æ¨¡å‹ï¼‰
â”‚   â””â”€â”€ migration.py               è¿ç§»å·¥å…·
â”‚
â”œâ”€â”€ api/                           ã€APIå±‚ã€‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crud.py                    CRUDæ“ä½œï¼ˆdb_query/save/getï¼‰
â”‚   â”œâ”€â”€ specialized.py             ç‰¹æ®Šæ“ä½œï¼ˆstore_action_infoç­‰ï¼‰
â”‚   â””â”€â”€ query_builder.py           æŸ¥è¯¢æ„å»ºå™¨
â”‚
â”œâ”€â”€ optimization/                  ã€ä¼˜åŒ–å±‚ã€‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ connection_pool.py         è¿æ¥æ± ç®¡ç†
â”‚   â”œâ”€â”€ batch_scheduler.py         æ‰¹é‡è°ƒåº¦
â”‚   â”œâ”€â”€ cache_manager.py           æ™ºèƒ½ç¼“å­˜
â”‚   â”œâ”€â”€ read_write_splitter.py     è¯»å†™åˆ†ç¦»
â”‚   â””â”€â”€ preloader.py               é¢„åŠ è½½å™¨
â”‚
â”œâ”€â”€ config/                        ã€é…ç½®å±‚ã€‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ database_config.py         æ•°æ®åº“é…ç½®
â”‚   â””â”€â”€ optimization_config.py     ä¼˜åŒ–é…ç½®
â”‚
â””â”€â”€ utils/                         ã€å·¥å…·å±‚ã€‘
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ exceptions.py              ç»Ÿä¸€å¼‚å¸¸
    â”œâ”€â”€ decorators.py              è£…é¥°å™¨ï¼ˆç¼“å­˜ã€é‡è¯•ç­‰ï¼‰
    â””â”€â”€ monitoring.py              æ€§èƒ½ç›‘æ§
```

### èŒè´£åˆ’åˆ†

#### Core å±‚ï¼ˆæ ¸å¿ƒå±‚ï¼‰
| æ–‡ä»¶ | èŒè´£ | ä¾èµ– |
|------|------|------|
| `engine.py` | åˆ›å»ºå’Œç®¡ç†æ•°æ®åº“å¼•æ“ï¼Œå•ä¾‹æ¨¡å¼ | config |
| `session.py` | æä¾›ä¼šè¯å·¥å‚å’Œä¸Šä¸‹æ–‡ç®¡ç†å™¨ | engine, optimization |
| `models.py` | å®šä¹‰æ‰€æœ‰SQLAlchemyæ¨¡å‹ | engine |
| `migration.py` | æ•°æ®åº“ç»“æ„è‡ªåŠ¨è¿ç§» | engine, models |

#### API å±‚ï¼ˆæ¥å£å±‚ï¼‰
| æ–‡ä»¶ | èŒè´£ | ä¾èµ– |
|------|------|------|
| `crud.py` | å®ç°db_query/db_save/db_get | session, models |
| `specialized.py` | ç‰¹æ®Šä¸šåŠ¡æ“ä½œ | crud |
| `query_builder.py` | æ„å»ºå¤æ‚æŸ¥è¯¢æ¡ä»¶ | - |

#### Optimization å±‚ï¼ˆä¼˜åŒ–å±‚ï¼‰
| æ–‡ä»¶ | èŒè´£ | ä¾èµ– |
|------|------|------|
| `connection_pool.py` | é€æ˜è¿æ¥å¤ç”¨ | session |
| `batch_scheduler.py` | æ‰¹é‡æ“ä½œè°ƒåº¦ | session |
| `cache_manager.py` | å¤šçº§ç¼“å­˜ç®¡ç† | - |
| `read_write_splitter.py` | è¯»å†™åˆ†ç¦»è·¯ç”± | engine |
| `preloader.py` | æ•°æ®é¢„åŠ è½½ | cache_manager |

---

## âš¡ é«˜é¢‘è¯»å†™ä¼˜åŒ–

### é—®é¢˜åˆ†æ

é€šè¿‡ä»£ç åˆ†æï¼Œè¯†åˆ«å‡ºä»¥ä¸‹é«˜é¢‘æ“ä½œåœºæ™¯ï¼š

#### é«˜é¢‘è¯»å–åœºæ™¯
1. **ChatStreams æŸ¥è¯¢** - æ¯æ¡æ¶ˆæ¯éƒ½è¦æŸ¥è¯¢èŠå¤©æµ
2. **Messages å†å²æŸ¥è¯¢** - æ„å»ºä¸Šä¸‹æ–‡æ—¶é¢‘ç¹æŸ¥è¯¢
3. **PersonInfo æŸ¥è¯¢** - æ¯æ¬¡äº¤äº’éƒ½è¦æŸ¥ç”¨æˆ·ä¿¡æ¯
4. **Emoji/Images æŸ¥è¯¢** - å‘é€è¡¨æƒ…æ—¶æŸ¥è¯¢
5. **UserRelationships æŸ¥è¯¢** - å…³ç³»ç³»ç»Ÿé¢‘ç¹è¯»å–

#### é«˜é¢‘å†™å…¥åœºæ™¯
1. **Messages æ’å…¥** - æ¯æ¡æ¶ˆæ¯éƒ½è¦å†™å…¥
2. **LLMUsage æ’å…¥** - æ¯æ¬¡LLMè°ƒç”¨éƒ½è®°å½•
3. **ActionRecords æ’å…¥** - æ¯ä¸ªåŠ¨ä½œéƒ½è®°å½•
4. **ChatStreams æ›´æ–°** - æ›´æ–°æ´»è·ƒæ—¶é—´å’ŒçŠ¶æ€

### ä¼˜åŒ–ç­–ç•¥è®¾è®¡

#### 1ï¸âƒ£ å¤šçº§ç¼“å­˜ç³»ç»Ÿ

```python
# optimization/cache_manager.py

from typing import Any, Optional, Callable
from dataclasses import dataclass
from datetime import timedelta
import asyncio
from collections import OrderedDict

@dataclass
class CacheConfig:
    """ç¼“å­˜é…ç½®"""
    l1_size: int = 1000           # L1ç¼“å­˜å¤§å°ï¼ˆå†…å­˜LRUï¼‰
    l1_ttl: float = 60.0          # L1 TTLï¼ˆç§’ï¼‰
    l2_size: int = 10000          # L2ç¼“å­˜å¤§å°ï¼ˆå†…å­˜LRUï¼‰
    l2_ttl: float = 300.0         # L2 TTLï¼ˆç§’ï¼‰
    enable_write_through: bool = True   # å†™ç©¿é€
    enable_write_back: bool = False     # å†™å›ï¼ˆé£é™©è¾ƒé«˜ï¼‰


class MultiLevelCache:
    """å¤šçº§ç¼“å­˜ç®¡ç†å™¨
    
    L1: çƒ­æ•°æ®ç¼“å­˜ï¼ˆ1000æ¡ï¼Œ60ç§’ï¼‰- æé«˜é¢‘è®¿é—®
    L2: æ¸©æ•°æ®ç¼“å­˜ï¼ˆ10000æ¡ï¼Œ300ç§’ï¼‰- é«˜é¢‘è®¿é—®
    L3: æ•°æ®åº“
    
    ç­–ç•¥ï¼š
    - è¯»å–ï¼šL1 â†’ L2 â†’ DBï¼Œå›å¡«åˆ°ä¸Šå±‚
    - å†™å…¥ï¼šå†™ç©¿é€ï¼ˆåŒæ­¥æ›´æ–°æ‰€æœ‰å±‚ï¼‰
    - å¤±æ•ˆï¼šTTL + LRU
    """
    
    def __init__(self, config: CacheConfig):
        self.config = config
        self.l1_cache: OrderedDict = OrderedDict()
        self.l2_cache: OrderedDict = OrderedDict()
        self.l1_timestamps: dict = {}
        self.l2_timestamps: dict = {}
        self.stats = {
            "l1_hits": 0,
            "l2_hits": 0,
            "db_hits": 0,
            "writes": 0,
        }
        self._lock = asyncio.Lock()
    
    async def get(
        self, 
        key: str, 
        fetch_func: Callable,
        ttl_override: Optional[float] = None
    ) -> Any:
        """è·å–æ•°æ®ï¼Œè‡ªåŠ¨å›å¡«"""
        # L1 æŸ¥æ‰¾
        if key in self.l1_cache:
            if self._is_valid(key, self.l1_timestamps, self.config.l1_ttl):
                self.stats["l1_hits"] += 1
                # LRUæ›´æ–°
                self.l1_cache.move_to_end(key)
                return self.l1_cache[key]
        
        # L2 æŸ¥æ‰¾
        if key in self.l2_cache:
            if self._is_valid(key, self.l2_timestamps, self.config.l2_ttl):
                self.stats["l2_hits"] += 1
                value = self.l2_cache[key]
                # å›å¡«åˆ°L1
                await self._set_l1(key, value)
                return value
        
        # ä»æ•°æ®åº“è·å–
        self.stats["db_hits"] += 1
        value = await fetch_func()
        
        # å›å¡«åˆ°L2å’ŒL1
        await self._set_l2(key, value)
        await self._set_l1(key, value)
        
        return value
    
    async def set(self, key: str, value: Any):
        """å†™å…¥æ•°æ®ï¼ˆå†™ç©¿é€ï¼‰"""
        async with self._lock:
            self.stats["writes"] += 1
            await self._set_l1(key, value)
            await self._set_l2(key, value)
    
    async def invalidate(self, key: str):
        """å¤±æ•ˆæŒ‡å®škey"""
        async with self._lock:
            self.l1_cache.pop(key, None)
            self.l2_cache.pop(key, None)
            self.l1_timestamps.pop(key, None)
            self.l2_timestamps.pop(key, None)
    
    async def invalidate_pattern(self, pattern: str):
        """å¤±æ•ˆåŒ¹é…æ¨¡å¼çš„key"""
        import re
        regex = re.compile(pattern)
        
        async with self._lock:
            for key in list(self.l1_cache.keys()):
                if regex.match(key):
                    del self.l1_cache[key]
                    self.l1_timestamps.pop(key, None)
            
            for key in list(self.l2_cache.keys()):
                if regex.match(key):
                    del self.l2_cache[key]
                    self.l2_timestamps.pop(key, None)
    
    def _is_valid(self, key: str, timestamps: dict, ttl: float) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        import time
        if key not in timestamps:
            return False
        return time.time() - timestamps[key] < ttl
    
    async def _set_l1(self, key: str, value: Any):
        """è®¾ç½®L1ç¼“å­˜"""
        import time
        if len(self.l1_cache) >= self.config.l1_size:
            # LRUæ·˜æ±°
            oldest = next(iter(self.l1_cache))
            del self.l1_cache[oldest]
            self.l1_timestamps.pop(oldest, None)
        
        self.l1_cache[key] = value
        self.l1_timestamps[key] = time.time()
    
    async def _set_l2(self, key: str, value: Any):
        """è®¾ç½®L2ç¼“å­˜"""
        import time
        if len(self.l2_cache) >= self.config.l2_size:
            # LRUæ·˜æ±°
            oldest = next(iter(self.l2_cache))
            del self.l2_cache[oldest]
            self.l2_timestamps.pop(oldest, None)
        
        self.l2_cache[key] = value
        self.l2_timestamps[key] = time.time()
    
    def get_stats(self) -> dict:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total_hits = self.stats["l1_hits"] + self.stats["l2_hits"] + self.stats["db_hits"]
        if total_hits == 0:
            hit_rate = 0
        else:
            hit_rate = (self.stats["l1_hits"] + self.stats["l2_hits"]) / total_hits * 100
        
        return {
            **self.stats,
            "l1_size": len(self.l1_cache),
            "l2_size": len(self.l2_cache),
            "hit_rate": f"{hit_rate:.2f}%",
            "total_requests": total_hits,
        }


# å…¨å±€ç¼“å­˜å®ä¾‹
_cache_manager: Optional[MultiLevelCache] = None


def get_cache_manager() -> MultiLevelCache:
    """è·å–å…¨å±€ç¼“å­˜ç®¡ç†å™¨"""
    global _cache_manager
    if _cache_manager is None:
        _cache_manager = MultiLevelCache(CacheConfig())
    return _cache_manager
```

#### 2ï¸âƒ£ æ™ºèƒ½é¢„åŠ è½½å™¨

```python
# optimization/preloader.py

import asyncio
from typing import List, Dict, Any
from collections import defaultdict

class DataPreloader:
    """æ•°æ®é¢„åŠ è½½å™¨
    
    ç­–ç•¥ï¼š
    1. ä¼šè¯å¯åŠ¨æ—¶é¢„åŠ è½½è¯¥èŠå¤©æµçš„æœ€è¿‘æ¶ˆæ¯
    2. å®šæœŸé¢„åŠ è½½çƒ­é—¨ç”¨æˆ·çš„PersonInfo
    3. é¢„åŠ è½½å¸¸ç”¨è¡¨æƒ…å’Œå›¾ç‰‡
    """
    
    def __init__(self):
        self.preload_tasks: Dict[str, asyncio.Task] = {}
        self.access_patterns = defaultdict(int)  # è®¿é—®æ¨¡å¼ç»Ÿè®¡
    
    async def preload_chat_stream_context(
        self, 
        stream_id: str,
        message_limit: int = 50
    ):
        """é¢„åŠ è½½èŠå¤©æµä¸Šä¸‹æ–‡"""
        from ..api.crud import db_get
        from ..core.models import Messages, ChatStreams, PersonInfo
        from .cache_manager import get_cache_manager
        
        cache = get_cache_manager()
        
        # 1. é¢„åŠ è½½ChatStream
        stream_key = f"chat_stream:{stream_id}"
        if stream_key not in cache.l1_cache:
            stream = await db_get(
                ChatStreams,
                filters={"stream_id": stream_id},
                single_result=True
            )
            if stream:
                await cache.set(stream_key, stream)
        
        # 2. é¢„åŠ è½½æœ€è¿‘æ¶ˆæ¯
        messages = await db_get(
            Messages,
            filters={"chat_id": stream_id},
            order_by="-time",
            limit=message_limit
        )
        
        # æ‰¹é‡ç¼“å­˜æ¶ˆæ¯
        for msg in messages:
            msg_key = f"message:{msg['message_id']}"
            await cache.set(msg_key, msg)
        
        # 3. é¢„åŠ è½½ç›¸å…³ç”¨æˆ·ä¿¡æ¯
        user_ids = set()
        for msg in messages:
            if msg.get("user_id"):
                user_ids.add(msg["user_id"])
        
        # æ‰¹é‡æŸ¥è¯¢ç”¨æˆ·ä¿¡æ¯
        if user_ids:
            users = await db_get(
                PersonInfo,
                filters={"user_id": {"$in": list(user_ids)}}
            )
            for user in users:
                user_key = f"person_info:{user['user_id']}"
                await cache.set(user_key, user)
    
    async def preload_hot_emojis(self, limit: int = 100):
        """é¢„åŠ è½½çƒ­é—¨è¡¨æƒ…"""
        from ..api.crud import db_get
        from ..core.models import Emoji
        from .cache_manager import get_cache_manager
        
        cache = get_cache_manager()
        
        # æŒ‰ä½¿ç”¨æ¬¡æ•°æ’åº
        hot_emojis = await db_get(
            Emoji,
            order_by="-usage_count",
            limit=limit
        )
        
        for emoji in hot_emojis:
            emoji_key = f"emoji:{emoji['emoji_hash']}"
            await cache.set(emoji_key, emoji)
    
    async def schedule_preload_task(
        self,
        task_name: str,
        coro,
        interval: float = 300.0  # 5åˆ†é’Ÿ
    ):
        """å®šæœŸæ‰§è¡Œé¢„åŠ è½½ä»»åŠ¡"""
        async def _task():
            while True:
                try:
                    await coro
                    await asyncio.sleep(interval)
                except asyncio.CancelledError:
                    break
                except Exception as e:
                    logger.error(f"é¢„åŠ è½½ä»»åŠ¡ {task_name} å¤±è´¥: {e}")
                    await asyncio.sleep(interval)
        
        task = asyncio.create_task(_task())
        self.preload_tasks[task_name] = task
    
    async def stop_all_tasks(self):
        """åœæ­¢æ‰€æœ‰é¢„åŠ è½½ä»»åŠ¡"""
        for task in self.preload_tasks.values():
            task.cancel()
        
        await asyncio.gather(*self.preload_tasks.values(), return_exceptions=True)
        self.preload_tasks.clear()


# å…¨å±€é¢„åŠ è½½å™¨
_preloader: Optional[DataPreloader] = None


def get_preloader() -> DataPreloader:
    """è·å–å…¨å±€é¢„åŠ è½½å™¨"""
    global _preloader
    if _preloader is None:
        _preloader = DataPreloader()
    return _preloader
```

#### 3ï¸âƒ£ å¢å¼ºæ‰¹é‡è°ƒåº¦å™¨

```python
# optimization/batch_scheduler.py

from typing import List, Dict, Any, Callable
from dataclasses import dataclass
import asyncio
import time

@dataclass
class SmartBatchConfig:
    """æ™ºèƒ½æ‰¹é‡é…ç½®"""
    # åŸºç¡€é…ç½®
    batch_size: int = 100              # å¢åŠ æ‰¹é‡å¤§å°
    max_wait_time: float = 0.05        # å‡å°‘ç­‰å¾…æ—¶é—´ï¼ˆ50msï¼‰
    
    # æ™ºèƒ½è°ƒæ•´
    enable_adaptive: bool = True       # å¯ç”¨è‡ªé€‚åº”æ‰¹é‡å¤§å°
    min_batch_size: int = 10
    max_batch_size: int = 500
    
    # ä¼˜å…ˆçº§é…ç½®
    high_priority_models: List[str] = None  # é«˜ä¼˜å…ˆçº§æ¨¡å‹
    
    # è‡ªåŠ¨é™çº§
    enable_auto_degradation: bool = True
    degradation_threshold: float = 1.0  # è¶…è¿‡1ç§’é™çº§ä¸ºç›´æ¥å†™å…¥


class EnhancedBatchScheduler:
    """å¢å¼ºçš„æ‰¹é‡è°ƒåº¦å™¨
    
    æ”¹è¿›ï¼š
    1. è‡ªé€‚åº”æ‰¹é‡å¤§å°
    2. ä¼˜å…ˆçº§é˜Ÿåˆ—
    3. è‡ªåŠ¨é™çº§ä¿æŠ¤
    4. å†™å…¥ç¡®è®¤æœºåˆ¶
    """
    
    def __init__(self, config: SmartBatchConfig):
        self.config = config
        self.queues: Dict[str, asyncio.Queue] = {}
        self.pending_operations: Dict[str, List] = {}
        self.scheduler_tasks: Dict[str, asyncio.Task] = {}
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            "avg_batch_size": 0,
            "avg_latency": 0,
            "total_batches": 0,
        }
        
        self._lock = asyncio.Lock()
        self._running = False
    
    async def schedule_write(
        self,
        model_class: Any,
        operation_type: str,  # 'insert', 'update', 'delete'
        data: Dict[str, Any],
        priority: int = 0,  # 0=normal, 1=high, -1=low
    ) -> asyncio.Future:
        """è°ƒåº¦å†™å…¥æ“ä½œ
        
        Returns:
            Futureå¯¹è±¡ï¼Œå¯awaitç­‰å¾…æ“ä½œå®Œæˆ
        """
        queue_key = f"{model_class.__name__}_{operation_type}"
        
        # ç¡®ä¿é˜Ÿåˆ—å­˜åœ¨
        if queue_key not in self.queues:
            async with self._lock:
                if queue_key not in self.queues:
                    self.queues[queue_key] = asyncio.Queue()
                    self.pending_operations[queue_key] = []
                    # å¯åŠ¨è°ƒåº¦å™¨
                    task = asyncio.create_task(
                        self._scheduler_loop(queue_key, model_class, operation_type)
                    )
                    self.scheduler_tasks[queue_key] = task
        
        # åˆ›å»ºFuture
        future = asyncio.get_event_loop().create_future()
        
        # åŠ å…¥é˜Ÿåˆ—
        operation = {
            "data": data,
            "priority": priority,
            "future": future,
            "timestamp": time.time(),
        }
        
        await self.queues[queue_key].put(operation)
        
        return future
    
    async def _scheduler_loop(
        self,
        queue_key: str,
        model_class: Any,
        operation_type: str
    ):
        """è°ƒåº¦å™¨ä¸»å¾ªç¯"""
        while self._running:
            try:
                # æ”¶é›†ä¸€æ‰¹æ“ä½œ
                batch = []
                deadline = time.time() + self.config.max_wait_time
                
                while len(batch) < self.config.batch_size:
                    timeout = deadline - time.time()
                    if timeout <= 0:
                        break
                    
                    try:
                        operation = await asyncio.wait_for(
                            self.queues[queue_key].get(),
                            timeout=timeout
                        )
                        batch.append(operation)
                    except asyncio.TimeoutError:
                        break
                
                if batch:
                    # æ‰§è¡Œæ‰¹é‡æ“ä½œ
                    await self._execute_batch(
                        model_class,
                        operation_type,
                        batch
                    )
            
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"æ‰¹é‡è°ƒåº¦å™¨é”™è¯¯ [{queue_key}]: {e}")
                await asyncio.sleep(0.1)
    
    async def _execute_batch(
        self,
        model_class: Any,
        operation_type: str,
        batch: List[Dict]
    ):
        """æ‰§è¡Œæ‰¹é‡æ“ä½œ"""
        start_time = time.time()
        
        try:
            from ..core.session import get_db_session
            from sqlalchemy import insert, update, delete
            
            async with get_db_session() as session:
                if operation_type == "insert":
                    # æ‰¹é‡æ’å…¥
                    data_list = [op["data"] for op in batch]
                    stmt = insert(model_class).values(data_list)
                    await session.execute(stmt)
                    await session.commit()
                    
                    # æ ‡è®°æ‰€æœ‰Futureä¸ºæˆåŠŸ
                    for op in batch:
                        if not op["future"].done():
                            op["future"].set_result(True)
                
                elif operation_type == "update":
                    # æ‰¹é‡æ›´æ–°
                    for op in batch:
                        stmt = update(model_class)
                        # æ ¹æ®dataä¸­çš„æ¡ä»¶æ›´æ–°
                        # ... å®ç°ç»†èŠ‚
                        await session.execute(stmt)
                    
                    await session.commit()
                    
                    for op in batch:
                        if not op["future"].done():
                            op["future"].set_result(True)
                
                # æ›´æ–°æ€§èƒ½ç»Ÿè®¡
                latency = time.time() - start_time
                self._update_stats(len(batch), latency)
        
        except Exception as e:
            # æ ‡è®°æ‰€æœ‰Futureä¸ºå¤±è´¥
            for op in batch:
                if not op["future"].done():
                    op["future"].set_exception(e)
            
            logger.error(f"æ‰¹é‡æ“ä½œå¤±è´¥: {e}")
    
    def _update_stats(self, batch_size: int, latency: float):
        """æ›´æ–°æ€§èƒ½ç»Ÿè®¡"""
        n = self.performance_stats["total_batches"]
        
        # ç§»åŠ¨å¹³å‡
        self.performance_stats["avg_batch_size"] = (
            (self.performance_stats["avg_batch_size"] * n + batch_size) / (n + 1)
        )
        self.performance_stats["avg_latency"] = (
            (self.performance_stats["avg_latency"] * n + latency) / (n + 1)
        )
        self.performance_stats["total_batches"] = n + 1
        
        # è‡ªé€‚åº”è°ƒæ•´æ‰¹é‡å¤§å°
        if self.config.enable_adaptive:
            if latency > 0.5:  # å¤ªæ…¢ï¼Œå‡å°æ‰¹é‡
                self.config.batch_size = max(
                    self.config.min_batch_size,
                    int(self.config.batch_size * 0.8)
                )
            elif latency < 0.1:  # å¾ˆå¿«ï¼Œå¢å¤§æ‰¹é‡
                self.config.batch_size = min(
                    self.config.max_batch_size,
                    int(self.config.batch_size * 1.2)
                )
    
    async def start(self):
        """å¯åŠ¨è°ƒåº¦å™¨"""
        self._running = True
    
    async def stop(self):
        """åœæ­¢è°ƒåº¦å™¨"""
        self._running = False
        
        # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
        for task in self.scheduler_tasks.values():
            task.cancel()
        
        await asyncio.gather(
            *self.scheduler_tasks.values(),
            return_exceptions=True
        )
        
        self.scheduler_tasks.clear()
```

#### 4ï¸âƒ£ è£…é¥°å™¨å·¥å…·

```python
# utils/decorators.py

from functools import wraps
from typing import Callable, Optional
import asyncio
import time

def cached(
    key_func: Callable = None,
    ttl: float = 60.0,
    cache_none: bool = False
):
    """ç¼“å­˜è£…é¥°å™¨
    
    Args:
        key_func: ç”Ÿæˆç¼“å­˜é”®çš„å‡½æ•°
        ttl: ç¼“å­˜æ—¶é—´
        cache_none: æ˜¯å¦ç¼“å­˜Noneå€¼
    
    Example:
        @cached(key_func=lambda stream_id: f"stream:{stream_id}", ttl=300)
        async def get_chat_stream(stream_id: str):
            # ...
    """
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            from ..optimization.cache_manager import get_cache_manager
            
            cache = get_cache_manager()
            
            # ç”Ÿæˆç¼“å­˜é”®
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                # é»˜è®¤é”®ï¼šå‡½æ•°å+å‚æ•°
                cache_key = f"{func.__name__}:{args}:{kwargs}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            async def fetch():
                return await func(*args, **kwargs)
            
            result = await cache.get(cache_key, fetch, ttl_override=ttl)
            
            # æ£€æŸ¥æ˜¯å¦ç¼“å­˜None
            if result is None and not cache_none:
                result = await func(*args, **kwargs)
            
            return result
        
        return wrapper
    return decorator


def batch_write(
    model_class,
    operation_type: str = "insert",
    priority: int = 0
):
    """æ‰¹é‡å†™å…¥è£…é¥°å™¨
    
    è‡ªåŠ¨å°†å†™å…¥æ“ä½œåŠ å…¥æ‰¹é‡è°ƒåº¦å™¨
    
    Example:
        @batch_write(Messages, operation_type="insert")
        async def save_message(data: dict):
            return data
    """
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            from ..optimization.batch_scheduler import get_batch_scheduler
            
            # æ‰§è¡ŒåŸå‡½æ•°è·å–æ•°æ®
            data = await func(*args, **kwargs)
            
            # åŠ å…¥æ‰¹é‡è°ƒåº¦å™¨
            scheduler = get_batch_scheduler()
            future = await scheduler.schedule_write(
                model_class,
                operation_type,
                data,
                priority
            )
            
            # ç­‰å¾…å®Œæˆ
            result = await future
            return result
        
        return wrapper
    return decorator


def retry(
    max_attempts: int = 3,
    delay: float = 0.5,
    backoff: float = 2.0,
    exceptions: tuple = (Exception,)
):
    """é‡è¯•è£…é¥°å™¨
    
    Args:
        max_attempts: æœ€å¤§é‡è¯•æ¬¡æ•°
        delay: åˆå§‹å»¶è¿Ÿ
        backoff: å»¶è¿Ÿå€æ•°
        exceptions: éœ€è¦é‡è¯•çš„å¼‚å¸¸ç±»å‹
    """
    def decorator(func: Callable):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_delay = delay
            
            for attempt in range(max_attempts):
                try:
                    return await func(*args, **kwargs)
                except exceptions as e:
                    if attempt == max_attempts - 1:
                        raise
                    
                    logger.warning(
                        f"å‡½æ•° {func.__name__} ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥: {e}ï¼Œ"
                        f"{current_delay}ç§’åé‡è¯•"
                    )
                    await asyncio.sleep(current_delay)
                    current_delay *= backoff
        
        return wrapper
    return decorator


def monitor_performance(func: Callable):
    """æ€§èƒ½ç›‘æ§è£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        
        try:
            result = await func(*args, **kwargs)
            return result
        finally:
            elapsed = time.time() - start_time
            
            # è®°å½•æ€§èƒ½æ•°æ®
            from ..utils.monitoring import record_metric
            record_metric(
                func.__name__,
                "execution_time",
                elapsed
            )
            
            # æ…¢æŸ¥è¯¢è­¦å‘Š
            if elapsed > 1.0:
                logger.warning(
                    f"æ…¢æ“ä½œæ£€æµ‹: {func.__name__} è€—æ—¶ {elapsed:.2f}ç§’"
                )
    
    return wrapper
```

#### 5ï¸âƒ£ é«˜é¢‘APIä¼˜åŒ–ç‰ˆæœ¬

```python
# api/optimized_crud.py

from typing import Optional, List, Dict, Any
from ..utils.decorators import cached, batch_write, monitor_performance
from ..core.models import ChatStreams, Messages, PersonInfo, Emoji

class OptimizedCRUD:
    """ä¼˜åŒ–çš„CRUDæ“ä½œ
    
    é’ˆå¯¹é«˜é¢‘åœºæ™¯æä¾›ä¼˜åŒ–ç‰ˆæœ¬çš„API
    """
    
    @staticmethod
    @cached(
        key_func=lambda stream_id: f"chat_stream:{stream_id}",
        ttl=300.0
    )
    @monitor_performance
    async def get_chat_stream(stream_id: str) -> Optional[Dict]:
        """è·å–èŠå¤©æµï¼ˆé«˜é¢‘ä¼˜åŒ–ï¼‰"""
        from .crud import db_get
        return await db_get(
            ChatStreams,
            filters={"stream_id": stream_id},
            single_result=True
        )
    
    @staticmethod
    @cached(
        key_func=lambda user_id: f"person_info:{user_id}",
        ttl=600.0  # 10åˆ†é’Ÿ
    )
    @monitor_performance
    async def get_person_info(user_id: str) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆé«˜é¢‘ä¼˜åŒ–ï¼‰"""
        from .crud import db_get
        return await db_get(
            PersonInfo,
            filters={"user_id": user_id},
            single_result=True
        )
    
    @staticmethod
    @cached(
        key_func=lambda chat_id, limit: f"messages:{chat_id}:{limit}",
        ttl=120.0  # 2åˆ†é’Ÿ
    )
    @monitor_performance
    async def get_recent_messages(
        chat_id: str,
        limit: int = 50
    ) -> List[Dict]:
        """è·å–æœ€è¿‘æ¶ˆæ¯ï¼ˆé«˜é¢‘ä¼˜åŒ–ï¼‰"""
        from .crud import db_get
        return await db_get(
            Messages,
            filters={"chat_id": chat_id},
            order_by="-time",
            limit=limit
        )
    
    @staticmethod
    @batch_write(Messages, operation_type="insert", priority=1)
    @monitor_performance
    async def save_message(data: Dict) -> Dict:
        """ä¿å­˜æ¶ˆæ¯ï¼ˆé«˜é¢‘ä¼˜åŒ–ï¼Œæ‰¹é‡å†™å…¥ï¼‰"""
        return data
    
    @staticmethod
    @cached(
        key_func=lambda emoji_hash: f"emoji:{emoji_hash}",
        ttl=3600.0  # 1å°æ—¶
    )
    @monitor_performance
    async def get_emoji(emoji_hash: str) -> Optional[Dict]:
        """è·å–è¡¨æƒ…ï¼ˆé«˜é¢‘ä¼˜åŒ–ï¼‰"""
        from .crud import db_get
        return await db_get(
            Emoji,
            filters={"emoji_hash": emoji_hash},
            single_result=True
        )
    
    @staticmethod
    async def update_chat_stream_active_time(
        stream_id: str,
        active_time: float
    ):
        """æ›´æ–°èŠå¤©æµæ´»è·ƒæ—¶é—´ï¼ˆé«˜é¢‘ä¼˜åŒ–ï¼Œå¼‚æ­¥æ‰¹é‡ï¼‰"""
        from ..optimization.batch_scheduler import get_batch_scheduler
        from ..optimization.cache_manager import get_cache_manager
        
        scheduler = get_batch_scheduler()
        
        # åŠ å…¥æ‰¹é‡æ›´æ–°
        await scheduler.schedule_write(
            ChatStreams,
            "update",
            {
                "stream_id": stream_id,
                "last_active_time": active_time
            },
            priority=0  # ä½ä¼˜å…ˆçº§
        )
        
        # å¤±æ•ˆç¼“å­˜
        cache = get_cache_manager()
        await cache.invalidate(f"chat_stream:{stream_id}")
```

---

## ğŸ“… å®æ–½è®¡åˆ’

### é˜¶æ®µä¸€ï¼šå‡†å¤‡é˜¶æ®µï¼ˆ1-2å¤©ï¼‰

#### ä»»åŠ¡æ¸…å•
- [x] å®Œæˆéœ€æ±‚åˆ†æå’Œæ¶æ„è®¾è®¡
- [ ] åˆ›å»ºæ–°ç›®å½•ç»“æ„
- [ ] ç¼–å†™æµ‹è¯•ç”¨ä¾‹ï¼ˆè¦†ç›–æ‰€æœ‰APIï¼‰
- [ ] è®¾ç½®æ€§èƒ½åŸºå‡†æµ‹è¯•

### é˜¶æ®µäºŒï¼šæ ¸å¿ƒå±‚é‡æ„ï¼ˆ2-3å¤©ï¼‰

#### ä»»åŠ¡æ¸…å•
- [ ] åˆ›å»º `core/engine.py` - è¿ç§»å¼•æ“ç®¡ç†é€»è¾‘
- [ ] åˆ›å»º `core/session.py` - è¿ç§»ä¼šè¯ç®¡ç†é€»è¾‘
- [ ] åˆ›å»º `core/models.py` - è¿ç§»å¹¶ç»Ÿä¸€æ‰€æœ‰æ¨¡å‹å®šä¹‰
- [ ] æ›´æ–°æ‰€æœ‰æ¨¡å‹åˆ° SQLAlchemy 2.0 ç±»å‹æ³¨è§£
- [ ] åˆ›å»º `core/migration.py` - è¿ç§»å·¥å…·
- [ ] è¿è¡Œæµ‹è¯•ï¼Œç¡®ä¿æ ¸å¿ƒåŠŸèƒ½æ­£å¸¸

### é˜¶æ®µä¸‰ï¼šä¼˜åŒ–å±‚å®ç°ï¼ˆ3-4å¤©ï¼‰

#### ä»»åŠ¡æ¸…å•
- [ ] å®ç° `optimization/cache_manager.py` - å¤šçº§ç¼“å­˜
- [ ] å®ç° `optimization/preloader.py` - æ™ºèƒ½é¢„åŠ è½½
- [ ] å¢å¼º `optimization/batch_scheduler.py` - æ™ºèƒ½æ‰¹é‡è°ƒåº¦
- [ ] å®ç° `optimization/connection_pool.py` - ä¼˜åŒ–è¿æ¥æ± 
- [ ] æ·»åŠ æ€§èƒ½ç›‘æ§å’Œç»Ÿè®¡

### é˜¶æ®µå››ï¼šAPIå±‚é‡æ„ï¼ˆ2-3å¤©ï¼‰

#### ä»»åŠ¡æ¸…å•
- [ ] åˆ›å»º `api/crud.py` - é‡æ„ CRUD æ“ä½œ
- [ ] åˆ›å»º `api/optimized_crud.py` - é«˜é¢‘ä¼˜åŒ–API
- [ ] åˆ›å»º `api/specialized.py` - ç‰¹æ®Šä¸šåŠ¡æ“ä½œ
- [ ] åˆ›å»º `api/query_builder.py` - æŸ¥è¯¢æ„å»ºå™¨
- [ ] å®ç°å‘åå…¼å®¹çš„APIåŒ…è£…

### é˜¶æ®µäº”ï¼šå·¥å…·å±‚å®Œå–„ï¼ˆ1-2å¤©ï¼‰

#### ä»»åŠ¡æ¸…å•
- [ ] åˆ›å»º `utils/exceptions.py` - ç»Ÿä¸€å¼‚å¸¸ä½“ç³»
- [ ] åˆ›å»º `utils/decorators.py` - è£…é¥°å™¨å·¥å…·
- [ ] åˆ›å»º `utils/monitoring.py` - æ€§èƒ½ç›‘æ§
- [ ] æ·»åŠ æ—¥å¿—å¢å¼º

### é˜¶æ®µå…­ï¼šå…¼å®¹å±‚å’Œè¿ç§»ï¼ˆ2-3å¤©ï¼‰

#### ä»»åŠ¡æ¸…å•
- [ ] å®Œå–„ `__init__.py` - å¯¼å‡ºæ‰€æœ‰API
- [ ] åˆ›å»ºå…¼å®¹æ€§é€‚é…å™¨ï¼ˆå¦‚æœéœ€è¦ï¼‰
- [ ] é€æ­¥è¿ç§»ç°æœ‰ä»£ç ä½¿ç”¨æ–°API
- [ ] æ·»åŠ å¼ƒç”¨è­¦å‘Šï¼ˆå¯¹äºå°†æ¥è¦ç§»é™¤çš„APIï¼‰

### é˜¶æ®µä¸ƒï¼šæµ‹è¯•å’Œä¼˜åŒ–ï¼ˆ2-3å¤©ï¼‰

#### ä»»åŠ¡æ¸…å•
- [ ] è¿è¡Œå®Œæ•´æµ‹è¯•å¥—ä»¶
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•å¯¹æ¯”
- [ ] å‹åŠ›æµ‹è¯•
- [ ] ä¿®å¤å‘ç°çš„é—®é¢˜
- [ ] æ€§èƒ½è°ƒä¼˜

### é˜¶æ®µå…«ï¼šæ–‡æ¡£å’Œæ¸…ç†ï¼ˆ1-2å¤©ï¼‰

#### ä»»åŠ¡æ¸…å•
- [ ] ç¼–å†™ä½¿ç”¨æ–‡æ¡£
- [ ] æ›´æ–°APIæ–‡æ¡£
- [ ] åˆ é™¤æ—§æ–‡ä»¶ï¼ˆå¦‚ .bakï¼‰
- [ ] ä»£ç å®¡æŸ¥
- [ ] å‡†å¤‡å‘å¸ƒ

### æ€»æ—¶é—´ä¼°è®¡ï¼š14-22å¤©

---

## ğŸ”§ å…·ä½“å®æ–½æ­¥éª¤

### æ­¥éª¤1ï¼šåˆ›å»ºæ–°ç›®å½•ç»“æ„

```bash
cd src/common/database

# åˆ›å»ºæ–°ç›®å½•
mkdir -p core api optimization config utils

# åˆ›å»º__init__.py
touch core/__init__.py
touch api/__init__.py
touch optimization/__init__.py
touch config/__init__.py
touch utils/__init__.py
```

### æ­¥éª¤2ï¼šå®ç°æ ¸å¿ƒå±‚

#### core/engine.py
```python
"""æ•°æ®åº“å¼•æ“ç®¡ç†
å•ä¸€èŒè´£ï¼šåˆ›å»ºå’Œç®¡ç†SQLAlchemyå¼•æ“
"""

from typing import Optional
from sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine
from ..config.database_config import get_database_config
from ..utils.exceptions import DatabaseInitializationError

_engine: Optional[AsyncEngine] = None
_engine_lock = None


async def get_engine() -> AsyncEngine:
    """è·å–å…¨å±€æ•°æ®åº“å¼•æ“ï¼ˆå•ä¾‹ï¼‰"""
    global _engine, _engine_lock
    
    if _engine is not None:
        return _engine
    
    # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
    import asyncio
    if _engine_lock is None:
        _engine_lock = asyncio.Lock()
    
    async with _engine_lock:
        # åŒé‡æ£€æŸ¥
        if _engine is not None:
            return _engine
        
        try:
            config = get_database_config()
            _engine = create_async_engine(
                config.url,
                **config.engine_kwargs
            )
            
            # SQLiteä¼˜åŒ–
            if config.db_type == "sqlite":
                await _enable_sqlite_optimizations(_engine)
            
            logger.info(f"æ•°æ®åº“å¼•æ“åˆå§‹åŒ–æˆåŠŸ: {config.db_type}")
            return _engine
        
        except Exception as e:
            raise DatabaseInitializationError(f"å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}") from e


async def close_engine():
    """å…³é—­æ•°æ®åº“å¼•æ“"""
    global _engine
    
    if _engine is not None:
        await _engine.dispose()
        _engine = None
        logger.info("æ•°æ®åº“å¼•æ“å·²å…³é—­")


async def _enable_sqlite_optimizations(engine: AsyncEngine):
    """å¯ç”¨SQLiteæ€§èƒ½ä¼˜åŒ–"""
    from sqlalchemy import text
    
    async with engine.begin() as conn:
        await conn.execute(text("PRAGMA journal_mode = WAL"))
        await conn.execute(text("PRAGMA synchronous = NORMAL"))
        await conn.execute(text("PRAGMA foreign_keys = ON"))
        await conn.execute(text("PRAGMA busy_timeout = 60000"))
    
    logger.info("SQLiteæ€§èƒ½ä¼˜åŒ–å·²å¯ç”¨")
```

#### core/session.py
```python
"""ä¼šè¯ç®¡ç†
å•ä¸€èŒè´£ï¼šæä¾›æ•°æ®åº“ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
"""

from contextlib import asynccontextmanager
from typing import AsyncGenerator
from sqlalchemy.ext.asyncio import AsyncSession, async_sessionmaker
from .engine import get_engine

_session_factory: Optional[async_sessionmaker] = None


async def get_session_factory() -> async_sessionmaker:
    """è·å–ä¼šè¯å·¥å‚"""
    global _session_factory
    
    if _session_factory is None:
        engine = await get_engine()
        _session_factory = async_sessionmaker(
            bind=engine,
            class_=AsyncSession,
            expire_on_commit=False
        )
    
    return _session_factory


@asynccontextmanager
async def get_db_session() -> AsyncGenerator[AsyncSession, None]:
    """
    è·å–æ•°æ®åº“ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    ä½¿ç”¨è¿æ¥æ± ä¼˜åŒ–ï¼Œé€æ˜å¤ç”¨è¿æ¥
    
    Example:
        async with get_db_session() as session:
            result = await session.execute(select(User))
    """
    from ..optimization.connection_pool import get_connection_pool_manager
    
    session_factory = await get_session_factory()
    pool_manager = get_connection_pool_manager()
    
    async with pool_manager.get_session(session_factory) as session:
        # SQLiteç‰¹å®šé…ç½®
        from ..config.database_config import get_database_config
        config = get_database_config()
        
        if config.db_type == "sqlite":
            from sqlalchemy import text
            try:
                await session.execute(text("PRAGMA busy_timeout = 60000"))
                await session.execute(text("PRAGMA foreign_keys = ON"))
            except Exception:
                pass  # å¤ç”¨è¿æ¥æ—¶å¯èƒ½å·²è®¾ç½®
        
        yield session
```

### æ­¥éª¤3ï¼šå®Œå–„ `__init__.py` ä¿æŒå…¼å®¹

```python
# src/common/database/__init__.py

"""
æ•°æ®åº“æ¨¡å—ç»Ÿä¸€å…¥å£

å¯¼å‡ºæ‰€æœ‰å¯¹å¤–APIï¼Œç¡®ä¿å‘åå…¼å®¹
"""

# === æ ¸å¿ƒå±‚å¯¼å‡º ===
from .core.engine import get_engine, close_engine
from .core.session import get_db_session
from .core.models import (
    Base,
    ChatStreams,
    Messages,
    ActionRecords,
    PersonInfo,
    LLMUsage,
    Emoji,
    Images,
    Videos,
    OnlineTime,
    Memory,
    Expression,
    ThinkingLog,
    GraphNodes,
    GraphEdges,
    Schedule,
    MonthlyPlan,
    BanUser,
    PermissionNodes,
    UserPermissions,
    UserRelationships,
    ImageDescriptions,
    CacheEntries,
    MaiZoneScheduleStatus,
    AntiInjectionStats,
    # ... æ‰€æœ‰æ¨¡å‹
)

# === APIå±‚å¯¼å‡º ===
from .api.crud import (
    db_query,
    db_save,
    db_get,
)
from .api.specialized import (
    store_action_info,
)
from .api.optimized_crud import OptimizedCRUD

# === ä¼˜åŒ–å±‚å¯¼å‡ºï¼ˆå¯é€‰ï¼‰ ===
from .optimization.cache_manager import get_cache_manager
from .optimization.batch_scheduler import get_batch_scheduler
from .optimization.preloader import get_preloader

# === æ—§æ¥å£å…¼å®¹ ===
from .database import (
    db,  # DatabaseProxy
    initialize_sql_database,
    stop_database,
)

# === æ¨¡å‹æ˜ å°„ï¼ˆå‘åå…¼å®¹ï¼‰ ===
MODEL_MAPPING = {
    "Messages": Messages,
    "ActionRecords": ActionRecords,
    "PersonInfo": PersonInfo,
    "ChatStreams": ChatStreams,
    "LLMUsage": LLMUsage,
    "Emoji": Emoji,
    "Images": Images,
    "Videos": Videos,
    "OnlineTime": OnlineTime,
    "Memory": Memory,
    "Expression": Expression,
    "ThinkingLog": ThinkingLog,
    "GraphNodes": GraphNodes,
    "GraphEdges": GraphEdges,
    "Schedule": Schedule,
    "MonthlyPlan": MonthlyPlan,
    "UserRelationships": UserRelationships,
    # ... å®Œæ•´æ˜ å°„
}

__all__ = [
    # ä¼šè¯ç®¡ç†
    "get_db_session",
    "get_engine",
    
    # CRUDæ“ä½œ
    "db_query",
    "db_save",
    "db_get",
    "store_action_info",
    
    # ä¼˜åŒ–API
    "OptimizedCRUD",
    
    # æ¨¡å‹
    "Base",
    "ChatStreams",
    "Messages",
    # ... æ‰€æœ‰æ¨¡å‹
    
    # æ¨¡å‹æ˜ å°„
    "MODEL_MAPPING",
    
    # åˆå§‹åŒ–
    "db",
    "initialize_sql_database",
    "stop_database",
    
    # ä¼˜åŒ–å·¥å…·
    "get_cache_manager",
    "get_batch_scheduler",
    "get_preloader",
]
```

---

## âš ï¸ é£é™©è¯„ä¼°ä¸å›æ»šæ–¹æ¡ˆ

### é£é™©è¯†åˆ«

| é£é™© | ç­‰çº§ | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|------|---------|
| APIæ¥å£å˜æ›´ | é«˜ | ç°æœ‰ä»£ç å´©æºƒ | å®Œæ•´çš„å…¼å®¹å±‚ + æµ‹è¯•è¦†ç›– |
| æ€§èƒ½ä¸‹é™ | ä¸­ | å“åº”å˜æ…¢ | æ€§èƒ½åŸºå‡†æµ‹è¯• + ç›‘æ§ |
| æ•°æ®ä¸ä¸€è‡´ | é«˜ | æ•°æ®æŸå | æ‰¹é‡æ“ä½œäº‹åŠ¡ä¿è¯ + å¤‡ä»½ |
| å†…å­˜æ³„æ¼ | ä¸­ | èµ„æºè€—å°½ | å‹åŠ›æµ‹è¯• + ç›‘æ§ |
| ç¼“å­˜ç©¿é€ | ä¸­ | æ•°æ®åº“å‹åŠ›å¢å¤§ | å¸ƒéš†è¿‡æ»¤å™¨ + ç©ºå€¼ç¼“å­˜ |

### å›æ»šæ–¹æ¡ˆ

#### å¿«é€Ÿå›æ»š
```bash
# å¦‚æœå‘ç°é‡å¤§é—®é¢˜ï¼Œç«‹å³å›æ»šåˆ°æ—§ç‰ˆæœ¬
git checkout <previous-commit>
# æˆ–ä½¿ç”¨featureåˆ†æ”¯å¼€å‘ï¼Œéšæ—¶å¯åˆ‡æ¢
git checkout main
```

#### æ¸è¿›å¼å›æ»š
```python
# åœ¨æ–°ä»£ç ä¸­æ·»åŠ å¼€å…³
from src.config.config import global_config

if global_config.database.use_legacy_mode:
    # ä½¿ç”¨æ—§å®ç°
    from .legacy.database import db_query
else:
    # ä½¿ç”¨æ–°å®ç°
    from .api.crud import db_query
```

### ç›‘æ§æŒ‡æ ‡

é‡æ„åéœ€è¦ç›‘æ§çš„å…³é”®æŒ‡æ ‡ï¼š
- APIå“åº”æ—¶é—´ï¼ˆP50, P95, P99ï¼‰
- æ•°æ®åº“è¿æ¥æ•°
- ç¼“å­˜å‘½ä¸­ç‡
- æ‰¹é‡æ“ä½œæˆåŠŸç‡
- é”™è¯¯ç‡å’Œå¼‚å¸¸
- å†…å­˜ä½¿ç”¨é‡

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### æ€§èƒ½æå‡ç›®æ ‡

| æŒ‡æ ‡ | å½“å‰ | ç›®æ ‡ | æå‡ |
|------|------|------|------|
| é«˜é¢‘è¯»å–å»¶è¿Ÿ | ~50ms | ~10ms | 80% â†“ |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | 85%+ | âˆ |
| å†™å…¥ååé‡ | ~100/s | ~1000/s | 10x â†‘ |
| è¿æ¥æ± åˆ©ç”¨ç‡ | ~60% | >90% | 50% â†‘ |
| æ•°æ®åº“è¿æ¥æ•° | åŠ¨æ€ | ç¨³å®š | æ›´ç¨³å®š |

### ä»£ç è´¨é‡æå‡

- âœ… å‡å°‘æ–‡ä»¶æ•°é‡å’Œä»£ç è¡Œæ•°
- âœ… èŒè´£æ›´æ¸…æ™°ï¼Œæ˜“äºç»´æŠ¤
- âœ… å®Œæ•´çš„ç±»å‹æ³¨è§£
- âœ… ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
- âœ… å®Œå–„çš„æ–‡æ¡£å’Œç¤ºä¾‹

---

## âœ… éªŒæ”¶æ ‡å‡†

### åŠŸèƒ½éªŒæ”¶
- [ ] æ‰€æœ‰ç°æœ‰æµ‹è¯•é€šè¿‡
- [ ] æ‰€æœ‰APIæ¥å£ä¿æŒå…¼å®¹
- [ ] æ— æ•°æ®ä¸¢å¤±æˆ–ä¸ä¸€è‡´
- [ ] æ— æ€§èƒ½å›å½’

### æ€§èƒ½éªŒæ”¶
- [ ] é«˜é¢‘è¯»å–å»¶è¿Ÿ < 15msï¼ˆP95ï¼‰
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 80%
- [ ] å†™å…¥ååé‡ > 500/s
- [ ] è¿æ¥æ± åˆ©ç”¨ç‡ > 85%

### ä»£ç è´¨é‡éªŒæ”¶
- [ ] ç±»å‹æ£€æŸ¥æ— é”™è¯¯
- [ ] ä»£ç è¦†ç›–ç‡ > 80%
- [ ] æ— é‡å¤§ä»£ç å¼‚å‘³
- [ ] æ–‡æ¡£å®Œæ•´

---

## ğŸ“ æ€»ç»“

æœ¬é‡æ„æ–¹æ¡ˆåœ¨ä¿æŒå®Œå…¨å‘åå…¼å®¹çš„å‰æä¸‹ï¼Œé€šè¿‡ä»¥ä¸‹æªæ–½ä¼˜åŒ–æ•°æ®åº“æ¨¡å—ï¼š

1. **æ¶æ„æ¸…æ™°åŒ–** - åˆ†å±‚è®¾è®¡ï¼ŒèŒè´£æ˜ç¡®
2. **å¤šçº§ç¼“å­˜** - L1/L2ç¼“å­˜ + æ™ºèƒ½å¤±æ•ˆ
3. **æ™ºèƒ½é¢„åŠ è½½** - å‡å°‘å†·å¯åŠ¨å»¶è¿Ÿ
4. **æ‰¹é‡è°ƒåº¦å¢å¼º** - è‡ªé€‚åº”æ‰¹é‡å¤§å° + ä¼˜å…ˆçº§é˜Ÿåˆ—
5. **è£…é¥°å™¨å·¥å…·** - ç®€åŒ–é«˜é¢‘æ“ä½œçš„ä¼˜åŒ–
6. **æ€§èƒ½ç›‘æ§** - å®æ—¶ç›‘æ§å’Œå‘Šè­¦

é¢„æœŸå¯å®ç°ï¼š
- é«˜é¢‘è¯»å–å»¶è¿Ÿé™ä½ 80%
- å†™å…¥ååé‡æå‡ 10 å€
- è¿æ¥æ± åˆ©ç”¨ç‡æå‡è‡³ 90% ä»¥ä¸Š

é£é™©å¯æ§ï¼Œå¯éšæ—¶å›æ»šã€‚
