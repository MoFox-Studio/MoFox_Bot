"""
LLM å·¥å…·æ¥å£ï¼šå®šä¹‰è®°å¿†ç³»ç»Ÿçš„å·¥å…· schema å’Œæ‰§è¡Œé€»è¾‘
"""

from __future__ import annotations

from typing import Any, Dict, List, Optional

from src.common.logger import get_logger
from src.memory_graph.core.builder import MemoryBuilder
from src.memory_graph.core.extractor import MemoryExtractor
from src.memory_graph.models import Memory, MemoryStatus
from src.memory_graph.storage.graph_store import GraphStore
from src.memory_graph.storage.persistence import PersistenceManager
from src.memory_graph.storage.vector_store import VectorStore
from src.memory_graph.utils.embeddings import EmbeddingGenerator

logger = get_logger(__name__)


class MemoryTools:
    """
    è®°å¿†ç³»ç»Ÿå·¥å…·é›†
    
    æä¾›ç»™ LLM ä½¿ç”¨çš„å·¥å…·æ¥å£ï¼š
    1. create_memory: åˆ›å»ºæ–°è®°å¿†
    2. link_memories: å…³è”ä¸¤ä¸ªè®°å¿†
    3. search_memories: æœç´¢è®°å¿†
    """

    def __init__(
        self,
        vector_store: VectorStore,
        graph_store: GraphStore,
        persistence_manager: PersistenceManager,
        embedding_generator: Optional[EmbeddingGenerator] = None,
    ):
        """
        åˆå§‹åŒ–å·¥å…·é›†
        
        Args:
            vector_store: å‘é‡å­˜å‚¨
            graph_store: å›¾å­˜å‚¨
            persistence_manager: æŒä¹…åŒ–ç®¡ç†å™¨
            embedding_generator: åµŒå…¥ç”Ÿæˆå™¨ï¼ˆå¯é€‰ï¼‰
        """
        self.vector_store = vector_store
        self.graph_store = graph_store
        self.persistence_manager = persistence_manager
        self._initialized = False

        # åˆå§‹åŒ–ç»„ä»¶
        self.extractor = MemoryExtractor()
        self.builder = MemoryBuilder(
            vector_store=vector_store,
            graph_store=graph_store,
            embedding_generator=embedding_generator,
        )

    async def _ensure_initialized(self):
        """ç¡®ä¿å‘é‡å­˜å‚¨å·²åˆå§‹åŒ–"""
        if not self._initialized:
            await self.vector_store.initialize()
            self._initialized = True

    @staticmethod
    def get_create_memory_schema() -> Dict[str, Any]:
        """
        è·å– create_memory å·¥å…·çš„ JSON schema
        
        Returns:
            å·¥å…· schema å®šä¹‰
        """
        return {
            "name": "create_memory",
            "description": """åˆ›å»ºä¸€ä¸ªæ–°çš„è®°å¿†èŠ‚ç‚¹ã€‚

âš ï¸ è®°å¿†åˆ›å»ºåŸåˆ™ï¼ˆå¿…é¡»éµå®ˆï¼‰ï¼š
1. **ä»·å€¼åˆ¤æ–­**ï¼šåªåˆ›å»ºå…·æœ‰é•¿æœŸä»·å€¼çš„å…³é”®ä¿¡æ¯ï¼Œé¿å…è®°å½•æ—¥å¸¸é—²èŠã€ç¤¼è²Œç”¨è¯­ã€é‡å¤ä¿¡æ¯
2. **ç»†ç²’åº¦åŸåˆ™**ï¼šæ¯æ¡è®°å¿†åªåŒ…å«ä¸€ä¸ªæ˜ç¡®çš„äº‹å®/äº‹ä»¶/è§‚ç‚¹ï¼Œé¿å…æ³›åŒ–
3. **åŸå­æ€§**ï¼šå¦‚æœä¸€å¥è¯åŒ…å«å¤šä¸ªé‡è¦ä¿¡æ¯ç‚¹ï¼Œæ‹†åˆ†æˆå¤šæ¡ç‹¬ç«‹è®°å¿†
4. **å…·ä½“æ€§**ï¼šè®°å½•å…·ä½“çš„äººã€äº‹ã€ç‰©ã€æ—¶é—´ã€åœ°ç‚¹ï¼Œé¿å…æ¨¡ç³Šæè¿°

âŒ ä¸åº”åˆ›å»ºè®°å¿†çš„æƒ…å†µï¼š
- æ™®é€šé—®å€™ã€æ„Ÿè°¢ã€ç¡®è®¤ç­‰ç¤¼è²Œæ€§å¯¹è¯
- å·²å­˜åœ¨çš„é‡å¤ä¿¡æ¯
- ä¸´æ—¶æ€§ã€ä¸€æ¬¡æ€§çš„çç¢ä¿¡æ¯
- çº¯ç²¹çš„åŠŸèƒ½æ“ä½œæŒ‡ä»¤ï¼ˆå¦‚"å¸®æˆ‘æŸ¥ä¸€ä¸‹"ï¼‰
- ç¼ºä¹ä¸Šä¸‹æ–‡çš„ç¢ç‰‡åŒ–ä¿¡æ¯

âœ… åº”è¯¥åˆ›å»ºè®°å¿†çš„æƒ…å†µï¼š
- ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼ˆå§“åã€èŒä¸šã€å…´è¶£ã€è”ç³»æ–¹å¼ç­‰ï¼‰
- é‡è¦äº‹ä»¶ï¼ˆé¡¹ç›®è¿›å±•ã€é‡å¤§å†³å®šã€å…³é”®è¡ŒåŠ¨ç­‰ï¼‰
- é•¿æœŸåå¥½/è§‚ç‚¹ï¼ˆå–œå¥½ã€ä»·å€¼è§‚ã€ä¹ æƒ¯ç­‰ï¼‰
- äººé™…å…³ç³»å˜åŒ–ï¼ˆæ–°æœ‹å‹ã€åˆä½œå…³ç³»ç­‰ï¼‰
- å…·ä½“è®¡åˆ’/ç›®æ ‡ï¼ˆæ˜ç¡®çš„å¾…åŠäº‹é¡¹ã€é•¿æœŸç›®æ ‡ç­‰ï¼‰

ğŸ“ æ‹†åˆ†ç¤ºä¾‹ï¼š
- âŒ "ç”¨æˆ·å–œæ¬¢ç¼–ç¨‹ï¼Œæœ€è¿‘åœ¨å­¦Pythonå’Œæœºå™¨å­¦ä¹ " â†’ è¿‡äºæ³›åŒ–
- âœ… æ‹†åˆ†ä¸º3æ¡ï¼š
  1. "ç”¨æˆ·å–œæ¬¢ç¼–ç¨‹"ï¼ˆè§‚ç‚¹ï¼‰
  2. "ç”¨æˆ·æ­£åœ¨å­¦ä¹ Python"ï¼ˆäº‹ä»¶ï¼‰
  3. "ç”¨æˆ·æ­£åœ¨å­¦ä¹ æœºå™¨å­¦ä¹ "ï¼ˆäº‹ä»¶ï¼‰

è®°å¿†ç»“æ„ï¼šä¸»ä½“ + ç±»å‹ + ä¸»é¢˜ + å®¢ä½“ï¼ˆå¯é€‰ï¼‰+ å±æ€§""",
            "parameters": {
                "type": "object",
                "properties": {
                    "subject": {
                        "type": "string",
                        "description": "è®°å¿†çš„ä¸»ä½“ï¼Œé€šå¸¸æ˜¯'ç”¨æˆ·'æˆ–å…·ä½“çš„äººåï¼ˆé¿å…ä½¿ç”¨'æˆ‘'ï¼‰",
                    },
                    "memory_type": {
                        "type": "string",
                        "enum": ["äº‹ä»¶", "äº‹å®", "å…³ç³»", "è§‚ç‚¹"],
                        "description": "è®°å¿†ç±»å‹ï¼š\n- äº‹ä»¶ï¼šæ—¶é—´ç»‘å®šçš„å…·ä½“åŠ¨ä½œï¼ˆå¦‚'å®Œæˆé¡¹ç›®'ã€'å­¦ä¹ è¯¾ç¨‹'ï¼‰\n- äº‹å®ï¼šç¨³å®šçš„å®¢è§‚çŠ¶æ€ï¼ˆå¦‚'èŒä¸šæ˜¯å·¥ç¨‹å¸ˆ'ã€'ä½åœ¨åŒ—äº¬'ï¼‰\n- å…³ç³»ï¼šäººé™…å…³ç³»ï¼ˆå¦‚'è®¤è¯†äº†æœ‹å‹'ã€'åŒäº‹å…³ç³»'ï¼‰\n- è§‚ç‚¹ï¼šä¸»è§‚è¯„ä»·/åå¥½ï¼ˆå¦‚'å–œæ¬¢Python'ã€'è®¤ä¸ºAIå¾ˆé‡è¦'ï¼‰",
                    },
                    "topic": {
                        "type": "string",
                        "description": "è®°å¿†çš„æ ¸å¿ƒä¸»é¢˜ï¼Œå¿…é¡»å…·ä½“ä¸”æ˜ç¡®ï¼ˆå¦‚'å­¦ä¹ PyTorchæ¡†æ¶'è€Œé'å­¦ä¹ ç¼–ç¨‹'ï¼‰",
                    },
                    "object": {
                        "type": "string",
                        "description": "è®°å¿†çš„å®¢ä½“/å¯¹è±¡ï¼Œä½œä¸ºä¸»é¢˜çš„è¡¥å……è¯´æ˜ï¼ˆå¦‚ä¸»é¢˜æ˜¯'å­¦ä¹ 'ï¼Œå®¢ä½“å¯ä»¥æ˜¯'PyTorchæ¡†æ¶'ï¼‰",
                    },
                    "attributes": {
                        "type": "object",
                        "description": "è®°å¿†çš„å…·ä½“å±æ€§ï¼ˆå°½é‡å¡«å†™ä»¥å¢åŠ è®°å¿†çš„ä¿¡æ¯å¯†åº¦ï¼‰",
                        "properties": {
                            "æ—¶é—´": {
                                "type": "string",
                                "description": "å…·ä½“æ—¶é—´è¡¨è¾¾å¼ï¼Œå¦‚'2025-11-05'ã€'ä»Šå¤©ä¸‹åˆ'ã€'æœ€è¿‘ä¸€å‘¨'ã€'3å¤©å‰'",
                            },
                            "åœ°ç‚¹": {
                                "type": "string", 
                                "description": "å…·ä½“åœ°ç‚¹ï¼ˆå¦‚æœç›¸å…³ï¼‰"
                            },
                            "åŸå› ": {
                                "type": "string", 
                                "description": "äº‹ä»¶å‘ç”Ÿçš„åŸå› æˆ–åŠ¨æœºï¼ˆå¦‚æœæ˜ç¡®ï¼‰"
                            },
                            "æ–¹å¼": {
                                "type": "string", 
                                "description": "å®Œæˆçš„æ–¹å¼æˆ–é€”å¾„ï¼ˆå¦‚æœç›¸å…³ï¼‰"
                            },
                            "ç»“æœ": {
                                "type": "string",
                                "description": "äº‹ä»¶çš„ç»“æœæˆ–å½±å“ï¼ˆå¦‚æœå·²çŸ¥ï¼‰"
                            },
                            "çŠ¶æ€": {
                                "type": "string",
                                "description": "å½“å‰çŠ¶æ€ï¼ˆå¦‚'è¿›è¡Œä¸­'ã€'å·²å®Œæˆ'ã€'è®¡åˆ’ä¸­'ï¼‰"
                            },
                        },
                        "additionalProperties": True,
                    },
                    "importance": {
                        "type": "number",
                        "minimum": 0.0,
                        "maximum": 1.0,
                        "description": "è®°å¿†çš„é‡è¦æ€§è¯„åˆ†ï¼ˆ0.0-1.0ï¼‰ï¼š\n- 0.3-0.4: æ¬¡è¦ä¿¡æ¯\n- 0.5-0.6: ä¸€èˆ¬ä¿¡æ¯\n- 0.7-0.8: é‡è¦ä¿¡æ¯ï¼ˆç”¨æˆ·æ˜ç¡®è¡¨è¾¾çš„åå¥½ã€é‡è¦äº‹ä»¶ï¼‰\n- 0.9-1.0: å…³é”®ä¿¡æ¯ï¼ˆæ ¸å¿ƒä¸ªäººä¿¡æ¯ã€é‡å¤§å†³å®šã€å¼ºçƒˆåå¥½ï¼‰\né»˜è®¤0.5",
                    },
                },
                "required": ["subject", "memory_type", "topic"],
            },
        }

    @staticmethod
    def get_link_memories_schema() -> Dict[str, Any]:
        """
        è·å– link_memories å·¥å…·çš„ JSON schema
        
        Returns:
            å·¥å…· schema å®šä¹‰
        """
        return {
            "name": "link_memories",
            "description": """æ‰‹åŠ¨å…³è”ä¸¤ä¸ªå·²å­˜åœ¨çš„è®°å¿†ã€‚

âš ï¸ ä½¿ç”¨å»ºè®®ï¼š
- ç³»ç»Ÿä¼šè‡ªåŠ¨å‘ç°è®°å¿†é—´çš„å…³è”å…³ç³»ï¼Œé€šå¸¸ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨æ­¤å·¥å…·
- ä»…åœ¨ä»¥ä¸‹æƒ…å†µä½¿ç”¨ï¼š
  1. ç”¨æˆ·æ˜ç¡®æŒ‡å‡ºä¸¤ä¸ªè®°å¿†ä¹‹é—´çš„å…³ç³»
  2. å‘ç°æ˜æ˜¾çš„å› æœå…³ç³»ä½†ç³»ç»Ÿæœªè‡ªåŠ¨å…³è”
  3. éœ€è¦å»ºç«‹ç‰¹æ®Šçš„å¼•ç”¨å…³ç³»

å…³ç³»ç±»å‹è¯´æ˜ï¼š
- å¯¼è‡´ï¼šAäº‹ä»¶/è¡Œä¸ºå¯¼è‡´Bäº‹ä»¶/ç»“æœï¼ˆå› æœå…³ç³»ï¼‰
- å¼•ç”¨ï¼šAè®°å¿†å¼•ç”¨/åŸºäºBè®°å¿†ï¼ˆçŸ¥è¯†å…³è”ï¼‰
- ç›¸ä¼¼ï¼šAå’ŒBæè¿°ç›¸ä¼¼çš„å†…å®¹ï¼ˆä¸»é¢˜ç›¸ä¼¼ï¼‰
- ç›¸åï¼šAå’ŒBè¡¨è¾¾ç›¸åçš„è§‚ç‚¹ï¼ˆå¯¹æ¯”å…³ç³»ï¼‰
- å…³è”ï¼šAå’ŒBå­˜åœ¨ä¸€èˆ¬æ€§å…³è”ï¼ˆå…¶ä»–å…³ç³»ï¼‰""",
            "parameters": {
                "type": "object",
                "properties": {
                    "source_memory_description": {
                        "type": "string",
                        "description": "æºè®°å¿†çš„å…³é”®æè¿°ï¼ˆç”¨äºæœç´¢å®šä½ï¼Œéœ€è¦è¶³å¤Ÿå…·ä½“ï¼‰",
                    },
                    "target_memory_description": {
                        "type": "string",
                        "description": "ç›®æ ‡è®°å¿†çš„å…³é”®æè¿°ï¼ˆç”¨äºæœç´¢å®šä½ï¼Œéœ€è¦è¶³å¤Ÿå…·ä½“ï¼‰",
                    },
                    "relation_type": {
                        "type": "string",
                        "enum": ["å¯¼è‡´", "å¼•ç”¨", "ç›¸ä¼¼", "ç›¸å", "å…³è”"],
                        "description": "å…³ç³»ç±»å‹ï¼ˆä»ä¸Šè¿°5ç§ç±»å‹ä¸­é€‰æ‹©æœ€åˆé€‚çš„ï¼‰",
                    },
                    "importance": {
                        "type": "number",
                        "minimum": 0.0,
                        "maximum": 1.0,
                        "description": "å…³ç³»çš„é‡è¦æ€§ï¼ˆ0.0-1.0ï¼‰ï¼š\n- 0.5-0.6: ä¸€èˆ¬å…³è”\n- 0.7-0.8: é‡è¦å…³è”\n- 0.9-1.0: å…³é”®å…³è”\né»˜è®¤0.6",
                    },
                },
                "required": [
                    "source_memory_description",
                    "target_memory_description",
                    "relation_type",
                ],
            },
        }

    @staticmethod
    def get_search_memories_schema() -> Dict[str, Any]:
        """
        è·å– search_memories å·¥å…·çš„ JSON schema
        
        Returns:
            å·¥å…· schema å®šä¹‰
        """
        return {
            "name": "search_memories",
            "description": """æœç´¢ç›¸å…³çš„è®°å¿†ï¼Œç”¨äºå›å¿†å’ŒæŸ¥æ‰¾å†å²ä¿¡æ¯ã€‚

ä½¿ç”¨åœºæ™¯ï¼š
- ç”¨æˆ·è¯¢é—®ä¹‹å‰çš„å¯¹è¯å†…å®¹
- éœ€è¦å›å¿†ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ã€åå¥½ã€ç»å†
- æŸ¥æ‰¾ç›¸å…³çš„å†å²äº‹ä»¶æˆ–è§‚ç‚¹
- åŸºäºä¸Šä¸‹æ–‡è¡¥å……ä¿¡æ¯

æœç´¢ç‰¹æ€§ï¼š
- è¯­ä¹‰æœç´¢ï¼šåŸºäºå†…å®¹ç›¸ä¼¼åº¦åŒ¹é…
- å›¾éå†ï¼šè‡ªåŠ¨æ‰©å±•ç›¸å…³è”çš„è®°å¿†
- æ—¶é—´è¿‡æ»¤ï¼šæŒ‰æ—¶é—´èŒƒå›´ç­›é€‰
- ç±»å‹è¿‡æ»¤ï¼šæŒ‰è®°å¿†ç±»å‹ç­›é€‰""",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢æŸ¥è¯¢ï¼ˆç”¨è‡ªç„¶è¯­è¨€æè¿°è¦æŸ¥æ‰¾çš„å†…å®¹ï¼Œå¦‚'ç”¨æˆ·çš„èŒä¸š'ã€'æœ€è¿‘çš„é¡¹ç›®'ã€'Pythonç›¸å…³çš„è®°å¿†'ï¼‰",
                    },
                    "memory_types": {
                        "type": "array",
                        "items": {
                            "type": "string",
                            "enum": ["äº‹ä»¶", "äº‹å®", "å…³ç³»", "è§‚ç‚¹"],
                        },
                        "description": "è®°å¿†ç±»å‹è¿‡æ»¤ï¼ˆå¯é€‰ï¼Œç•™ç©ºè¡¨ç¤ºæœç´¢æ‰€æœ‰ç±»å‹ï¼‰",
                    },
                    "time_range": {
                        "type": "object",
                        "properties": {
                            "start": {
                                "type": "string",
                                "description": "å¼€å§‹æ—¶é—´ï¼ˆå¦‚'3å¤©å‰'ã€'ä¸Šå‘¨'ã€'2025-11-01'ï¼‰",
                            },
                            "end": {
                                "type": "string",
                                "description": "ç»“æŸæ—¶é—´ï¼ˆå¦‚'ä»Šå¤©'ã€'ç°åœ¨'ã€'2025-11-05'ï¼‰",
                            },
                        },
                        "description": "æ—¶é—´èŒƒå›´ï¼ˆå¯é€‰ï¼Œç”¨äºæŸ¥æ‰¾ç‰¹å®šæ—¶é—´æ®µçš„è®°å¿†ï¼‰",
                    },
                    "top_k": {
                        "type": "integer",
                        "minimum": 1,
                        "maximum": 50,
                        "description": "è¿”å›ç»“æœæ•°é‡ï¼ˆ1-50ï¼Œé»˜è®¤10ï¼‰ã€‚æ ¹æ®éœ€æ±‚è°ƒæ•´ï¼š\n- å¿«é€ŸæŸ¥æ‰¾ï¼š3-5æ¡\n- ä¸€èˆ¬æœç´¢ï¼š10æ¡\n- å…¨é¢äº†è§£ï¼š20-30æ¡",
                    },
                    "expand_depth": {
                        "type": "integer",
                        "minimum": 0,
                        "maximum": 3,
                        "description": "å›¾æ‰©å±•æ·±åº¦ï¼ˆ0-3ï¼Œé»˜è®¤1ï¼‰ï¼š\n- 0: ä»…è¿”å›ç›´æ¥åŒ¹é…çš„è®°å¿†\n- 1: åŒ…å«ä¸€åº¦ç›¸å…³çš„è®°å¿†ï¼ˆæ¨èï¼‰\n- 2-3: åŒ…å«æ›´å¤šé—´æ¥ç›¸å…³çš„è®°å¿†ï¼ˆç”¨äºæ·±åº¦æ¢ç´¢ï¼‰",
                    },
                },
                "required": ["query"],
            },
        }

    async def create_memory(self, **params) -> Dict[str, Any]:
        """
        æ‰§è¡Œ create_memory å·¥å…·
        
        Args:
            **params: å·¥å…·å‚æ•°
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(f"åˆ›å»ºè®°å¿†: {params.get('subject')} - {params.get('topic')}")

            # 0. ç¡®ä¿åˆå§‹åŒ–
            await self._ensure_initialized()

            # 1. æå–å‚æ•°
            extracted = self.extractor.extract_from_tool_params(params)

            # 2. æ„å»ºè®°å¿†
            memory = await self.builder.build_memory(extracted)

            # 3. æ·»åŠ åˆ°å­˜å‚¨ï¼ˆæš‚å­˜çŠ¶æ€ï¼‰
            await self._add_memory_to_stores(memory)

            # 4. ä¿å­˜åˆ°ç£ç›˜
            await self.persistence_manager.save_graph_store(self.graph_store)

            logger.info(f"è®°å¿†åˆ›å»ºæˆåŠŸ: {memory.id}")

            return {
                "success": True,
                "memory_id": memory.id,
                "message": f"è®°å¿†å·²åˆ›å»º: {extracted['subject']} - {extracted['topic']}",
                "nodes_count": len(memory.nodes),
                "edges_count": len(memory.edges),
            }

        except Exception as e:
            logger.error(f"è®°å¿†åˆ›å»ºå¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "è®°å¿†åˆ›å»ºå¤±è´¥",
            }

    async def link_memories(self, **params) -> Dict[str, Any]:
        """
        æ‰§è¡Œ link_memories å·¥å…·
        
        Args:
            **params: å·¥å…·å‚æ•°
            
        Returns:
            æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(
                f"å…³è”è®°å¿†: {params.get('source_memory_description')} -> "
                f"{params.get('target_memory_description')}"
            )

            # 1. æå–å‚æ•°
            extracted = self.extractor.extract_link_params(params)

            # 2. æŸ¥æ‰¾æºè®°å¿†å’Œç›®æ ‡è®°å¿†
            source_memory = await self._find_memory_by_description(
                extracted["source_description"]
            )
            target_memory = await self._find_memory_by_description(
                extracted["target_description"]
            )

            if not source_memory:
                return {
                    "success": False,
                    "error": "æ‰¾ä¸åˆ°æºè®°å¿†",
                    "message": f"æœªæ‰¾åˆ°åŒ¹é…çš„æºè®°å¿†: {extracted['source_description']}",
                }

            if not target_memory:
                return {
                    "success": False,
                    "error": "æ‰¾ä¸åˆ°ç›®æ ‡è®°å¿†",
                    "message": f"æœªæ‰¾åˆ°åŒ¹é…çš„ç›®æ ‡è®°å¿†: {extracted['target_description']}",
                }

            # 3. åˆ›å»ºå…³è”è¾¹
            edge = await self.builder.link_memories(
                source_memory=source_memory,
                target_memory=target_memory,
                relation_type=extracted["relation_type"],
                importance=extracted["importance"],
            )

            # 4. æ·»åŠ è¾¹åˆ°å›¾å­˜å‚¨
            self.graph_store.graph.add_edge(
                edge.source_id,
                edge.target_id,
                relation=edge.relation,
                edge_type=edge.edge_type.value,
                importance=edge.importance,
                **edge.metadata
            )

            # 5. ä¿å­˜
            await self.persistence_manager.save_graph_store(self.graph_store)

            logger.info(f"è®°å¿†å…³è”æˆåŠŸ: {source_memory.id} -> {target_memory.id}")

            return {
                "success": True,
                "message": f"è®°å¿†å·²å…³è”: {extracted['relation_type']}",
                "source_memory_id": source_memory.id,
                "target_memory_id": target_memory.id,
                "relation_type": extracted["relation_type"],
            }

        except Exception as e:
            logger.error(f"è®°å¿†å…³è”å¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "è®°å¿†å…³è”å¤±è´¥",
            }

    async def search_memories(self, **params) -> Dict[str, Any]:
        """
        æ‰§è¡Œ search_memories å·¥å…·
        
        Args:
            **params: å·¥å…·å‚æ•°
            
        Returns:
            æœç´¢ç»“æœ
        """
        try:
            query = params.get("query", "")
            top_k = params.get("top_k", 10)
            expand_depth = params.get("expand_depth", 1)

            logger.info(f"æœç´¢è®°å¿†: {query} (top_k={top_k}, expand_depth={expand_depth})")

            # 0. ç¡®ä¿åˆå§‹åŒ–
            await self._ensure_initialized()

            # 1. ç”ŸæˆæŸ¥è¯¢åµŒå…¥
            if self.builder.embedding_generator:
                query_embedding = await self.builder.embedding_generator.generate(query)
            else:
                logger.warning("æœªé…ç½®åµŒå…¥ç”Ÿæˆå™¨ï¼Œä½¿ç”¨éšæœºå‘é‡")
                import numpy as np
                query_embedding = np.random.rand(384).astype(np.float32)

            # 2. å‘é‡æœç´¢
            node_types_filter = None
            if "memory_types" in params:
                # æ·»åŠ ç±»å‹è¿‡æ»¤
                pass

            similar_nodes = await self.vector_store.search_similar_nodes(
                query_embedding=query_embedding,
                limit=top_k * 2,  # å¤šå–ä¸€äº›ï¼Œåç»­è¿‡æ»¤
                node_types=node_types_filter,
            )

            # 3. æå–è®°å¿†ID
            memory_ids = set()
            for node_id, similarity, metadata in similar_nodes:
                if "memory_ids" in metadata:
                    ids = metadata["memory_ids"]
                    # ç¡®ä¿æ˜¯åˆ—è¡¨
                    if isinstance(ids, str):
                        import json
                        try:
                            ids = json.loads(ids)
                        except:
                            ids = [ids]
                    if isinstance(ids, list):
                        memory_ids.update(ids)

            # 4. è·å–å®Œæ•´è®°å¿†
            memories = []
            for memory_id in list(memory_ids)[:top_k]:
                memory = self.graph_store.get_memory_by_id(memory_id)
                if memory:
                    memories.append(memory)

            # 5. æ ¼å¼åŒ–ç»“æœ
            results = []
            for memory in memories:
                result = {
                    "memory_id": memory.id,
                    "importance": memory.importance,
                    "created_at": memory.created_at.isoformat(),
                    "summary": self._summarize_memory(memory),
                }
                results.append(result)

            logger.info(f"æœç´¢å®Œæˆ: æ‰¾åˆ° {len(results)} æ¡è®°å¿†")

            return {
                "success": True,
                "results": results,
                "total": len(results),
                "query": query,
            }

        except Exception as e:
            logger.error(f"è®°å¿†æœç´¢å¤±è´¥: {e}", exc_info=True)
            return {
                "success": False,
                "error": str(e),
                "message": "è®°å¿†æœç´¢å¤±è´¥",
                "results": [],
            }

    async def _add_memory_to_stores(self, memory: Memory):
        """å°†è®°å¿†æ·»åŠ åˆ°å­˜å‚¨"""
        # 1. æ·»åŠ åˆ°å›¾å­˜å‚¨
        self.graph_store.add_memory(memory)

        # 2. æ·»åŠ æœ‰åµŒå…¥çš„èŠ‚ç‚¹åˆ°å‘é‡å­˜å‚¨
        for node in memory.nodes:
            if node.embedding is not None:
                await self.vector_store.add_node(node)

    async def _find_memory_by_description(self, description: str) -> Optional[Memory]:
        """
        é€šè¿‡æè¿°æŸ¥æ‰¾è®°å¿†
        
        Args:
            description: è®°å¿†æè¿°
            
        Returns:
            æ‰¾åˆ°çš„è®°å¿†ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å› None
        """
        # ä½¿ç”¨è¯­ä¹‰æœç´¢æŸ¥æ‰¾æœ€ç›¸å…³çš„è®°å¿†
        if self.builder.embedding_generator:
            query_embedding = await self.builder.embedding_generator.generate(description)
        else:
            import numpy as np
            query_embedding = np.random.rand(384).astype(np.float32)

        # æœç´¢ç›¸ä¼¼èŠ‚ç‚¹
        similar_nodes = await self.vector_store.search_similar_nodes(
            query_embedding=query_embedding,
            limit=5,
        )

        if not similar_nodes:
            return None

        # è·å–æœ€ç›¸ä¼¼èŠ‚ç‚¹å…³è”çš„è®°å¿†
        node_id, similarity, metadata = similar_nodes[0]
        
        if "memory_ids" not in metadata or not metadata["memory_ids"]:
            return None
        
        ids = metadata["memory_ids"]
        
        # ç¡®ä¿æ˜¯åˆ—è¡¨
        if isinstance(ids, str):
            import json
            try:
                ids = json.loads(ids)
            except Exception as e:
                logger.warning(f"JSON è§£æå¤±è´¥: {e}")
                ids = [ids]
        
        if isinstance(ids, list) and ids:
            memory_id = ids[0]
            return self.graph_store.get_memory_by_id(memory_id)
        
        return None

    def _summarize_memory(self, memory: Memory) -> str:
        """ç”Ÿæˆè®°å¿†æ‘˜è¦"""
        if not memory.metadata:
            return "æœªçŸ¥è®°å¿†"

        subject = memory.metadata.get("subject", "")
        topic = memory.metadata.get("topic", "")
        memory_type = memory.metadata.get("memory_type", "")

        return f"{subject} - {memory_type}: {topic}"

    @staticmethod
    def get_all_tool_schemas() -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰å·¥å…·çš„ schema
        
        Returns:
            å·¥å…· schema åˆ—è¡¨
        """
        return [
            MemoryTools.get_create_memory_schema(),
            MemoryTools.get_link_memories_schema(),
            MemoryTools.get_search_memories_schema(),
        ]
